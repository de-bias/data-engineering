---
title: "pickwell-od"
format: html
editor: visual
---

# Import libraries

```{r}
library(dplyr)
library(sf)
library(ggplot2)
library(tmap)
library(viridis)
library(spdep)
library(sysfonts)
library(showtextdb)
library(classInt)
library(scales)
library(forcats)
library(spgwr)
library(arrow)
library(h3)
library(archive)
library(ggspatial)
library(data.table)
library(arrow)
library(lobstr)
```

# Set themes

```{r}
#| include = FALSE
source("./style/data-visualisation_theme.R")
```

# Data import

## Census and boundaries

```{r}
wd <- "/Volumes/rdm04/DEBIAS"
#wd_local <- "/Users/carmen/Documents/github/de-bias"

```

```{r}
# df_pop_census <- read.csv(paste0(wd, "/data/inputs/census/census2021-ts/census2021-ts001/census2021-ts001-ltla.csv")) %>% select(date, geography, geography.code, Residence.type..Total..measures..Value) %>% rename("code" = "geography.code", "name" = "geography", "pop" = "Residence.type..Total..measures..Value")

# df_boundaries <- st_read(paste0(wd, "/data/inputs/geographies/boundaries/OA_2021_EW_BFC_V8.gpkg")) %>% 
#   select(OA21CD, SHAPE) %>%
#   rename("code" = "OA21CD") %>% 
#   st_transform(df_boundaries, st_crs(4326))
# 
# df_boundaries_up <- st_read(paste0(wd, "/data/inputs/geographies/boundaries/RGN_Dec_2021_EN_BFC_2022.gpkg")) %>% 
#   st_simplify(preserveTopology = FALSE, dTolerance = 1000)
# 
# df_boundaries_hex <- st_read(paste0(wd, "/data/inputs/geographies/hexboundaries/uk-local-authority-districts-2021.geojson")) %>% 
#   st_transform(st_crs(df_boundaries_up)) %>% 
#   rename("code" = "id")
```

## Digital trace data from Pickwell

### pickwell

Read parquet dataset using arrow

```{r}
# Remove suffix "test" from the directory path if working with the full dataset. Test is for a smaller portion (e.g. one day)
data_parquet <- open_dataset("/Volumes/rdm04/DEBIAS/data/inputs/pickwell/uk_parquet/converted_parquet_test/part-0.parquet", format="parquet")   
```

Check size of object

```{r}
lobstr::obj_size(data_parquet)
```

Check schema

```{r}
data_parquet$schema
```

# Data processing

Aim: for each unique device, let's extract the place of residence as the hexagon where they've been seen most times between 10pm and 7 am.

The data will be stored in a dataset with two columns: device ID and hexagon (hex3 12 = 0.000307092 km2) of residence.

## Identify the unique devices and store their IDs in a dataframe

```{r}
df <- data_parquet %>% 
  select(device_aid) %>%
  filter(!is.na(device_aid)) %>% 
  distinct() %>%
  collect() 

```

## Create a column to store hex of home location

```{r}
df$home_hex12 <- NA
```

## For each unique device, find home location

```{r}
# Record the start time
start_time <- Sys.time()

for (i in 1:100) 
#for (i in 1:nrow(df)) 
  {
  # Filter the movement dataset to include data from one device only
  df_device <- data_parquet %>%
    select(device_aid, timestamp, longitude, latitude) %>%
    filter(device_aid == df$device_aid[i]) %>%
    collect()
  
  # Obtain the hour, weekday, and day corresponding to timestamps for the device
  # Filter to retain only night hours (23:00â€“7:00)
  df_device_home <- df_device %>%
    mutate(
      hour = as.POSIXlt(as.POSIXct(timestamp, origin = "1970-01-01", tz = "GMT"))$hour,
      wday = as.POSIXlt(as.POSIXct(timestamp, origin = "1970-01-01", tz = "GMT"))$wday,
      day = format(as.POSIXlt(timestamp, origin = "1970-01-01", tz = "GMT"), "%Y-%m-%d")
    ) %>%
    filter(hour <= 7 | hour >= 22)
  
  # Obtain H3 indexes at resolution 12 for each location
  coords <- df_device_home %>% st_drop_geometry()
  coords <- coords[, c("latitude", "longitude")]
  h3_indexes <- geo_to_h3(coords, 12)
  df_device_home$code_h3 <- h3_indexes
  
  # Note: if you would like to use OA, uncomment the code chunk below
  # Spatial join to attach OA of record (optional, depends on execution time)
  # execution_time <- system.time({
  #   df_device_home <- df_device_home %>%
  #     st_as_sf(coords = c("longitude", "latitude"), crs = 4326, remove = FALSE) %>%
  #     st_join(df_boundaries %>% select(code), left = TRUE)
  # })
  # print(execution_time)
  
  # Determine home location as the most common H3 index
  most_common_value <- df_device_home$code_h3 %>%
    table() %>%
    which.max() %>%
    names()
  
  # Calculate the percentage of rows where the most common value appears
  most_common_count <- df_device_home %>%
    filter(code_h3 == most_common_value) %>%
    nrow()
  percentage <- (most_common_count / nrow(df_device_home)) * 100
  
  # Update 'home_hex12' column in df if conditions are met
  if (percentage > 50 & most_common_count > 2) {
    df[i, "home_hex12"] <- most_common_value
  }
}

write_parquet(df, paste0(wd, "/data/outputs/pw/home-locations/hex/home-location_hex.parquet"))
saveRDS(df, paste0(wd, "/data/outputs/pw/home-locations/hex/home-location_hex.rds"))

# Record the end time
end_time <- Sys.time()

# Calculate and display the time difference
elapsed_time <- end_time - start_time
print(elapsed_time)
```

Next steps:

-   Optimize the code. Do this for several days, not just the "test day". Decide whether we filter out the Easter days.
